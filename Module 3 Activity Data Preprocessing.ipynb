{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h3 align=\"center\">__Module 3 Activity__</h3>\n",
    "# <h3 align=\"center\">__Assigned at the start of Module 3__</h3>\n",
    "# <h3 align=\"center\">__Due at the end of Module 3__</h3><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Discussion Forum Participation\n",
    "\n",
    "Each week, you are required to participate in the module’s discussion forum. The discussion forum consists of the week's Module Activity, which is released at the beginning of the module. You must complete/attempt the activity before you can post about the activity and anything that relates to the topic. \n",
    "\n",
    "## Grading of the Discussion\n",
    "\n",
    "### 1. Initial Post:\n",
    "Create your thread by **Day 5 (Saturday night at midnight, PST).**\n",
    "\n",
    "### 2. Responses:\n",
    "Respond to at least two other posts by **Day 7 (Monday night at midnight, PST).**\n",
    "\n",
    "---\n",
    "\n",
    "## Grading Criteria:\n",
    "\n",
    "Your participation will be graded as follows:\n",
    "\n",
    "### Full Credit (100 points):\n",
    "- Submit your initial post by **Day 5.**\n",
    "- Respond to at least two other posts by **Day 7.**\n",
    "\n",
    "### Half Credit (50 points):\n",
    "- If your initial post is late but you respond to two other posts.\n",
    "- If your initial post is on time but you fail to respond to at least two other posts.\n",
    "\n",
    "### No Credit (0 points):\n",
    "- If both your initial post and responses are late.\n",
    "- If you fail to submit an initial post and do not respond to any others.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Notes:\n",
    "\n",
    "- **Late Initial Posts:** Late posts will automatically receive half credit if two responses are completed on time.\n",
    "- **Substance Matters:** Responses must be thoughtful and constructive. Comments like “Great post!” or “I agree!” without further explanation will not earn credit.\n",
    "- **Balance Participation:** Aim to engage with threads that have fewer or no responses to ensure a balanced discussion.\n",
    "\n",
    "---\n",
    "\n",
    "## Avoid:\n",
    "- A number of posts within a very short time-frame, especially immediately prior to the posting deadline.\n",
    "- Posts that complement another post, and then consist of a summary of that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Activity: Building a Preprocessing Pipeline\n",
    "\n",
    "## Objective\n",
    "Learn how to build a preprocessing pipeline in scikit-learn and apply it to the famous Iris dataset. Gain hands-on experience in handling missing values, scaling features, and understanding the importance of preprocessing pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## Sample Code for Pipeline Syntax\n",
    "Here’s an example to help you understand how to create a pipeline. This pipeline imputes missing values using the mean:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Example dataset with missing values\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': [1.0, np.nan, 3.0],\n",
    "    'Feature2': [np.nan, 2.0, 3.0]\n",
    "})\n",
    "\n",
    "# Define a pipeline with an imputer\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Fit and transform the data\n",
    "processed_data = pipeline.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\nProcessed Data:\")\n",
    "print(processed_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Instructions\n",
    "\n",
    "## Dataset Preparation\n",
    "We will use the Iris dataset, randomly remove values to simulate missing data, and keep it in a Pandas DataFrame for you to preprocess.\n",
    "\n",
    "---\n",
    "\n",
    "## Your Task\n",
    "Build a preprocessing pipeline that:\n",
    "- Imputes missing values using the median.\n",
    "- Scales features to a `[0, 1]` range using `MinMaxScaler`.\n",
    "- Add at least one more preprocessing step.\n",
    "\n",
    "### Reflection\n",
    "At the end of the activity, answer the following questions:\n",
    "1. What challenges did you face while handling missing data?\n",
    "2. Why is it important to use a pipeline for preprocessing?\n",
    "---\n",
    "\n",
    "## Dataset Setup\n",
    "Run the following code to import the Iris dataset and simulate missing data. You will use this dataset for the activity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with Missing Values:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                NaN               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                NaN               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "5                5.4               3.9                1.7               0.4\n",
      "6                NaN               3.4                1.4               0.3\n",
      "7                5.0               NaN                NaN               0.2\n",
      "8                4.4               2.9                1.4               0.2\n",
      "9                4.9               3.1                1.5               0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Randomly introduce missing values in random cells\n",
    "np.random.seed(42)\n",
    "total_cells = data.size\n",
    "num_missing = int(0.1 * total_cells)  # 10% of total cells\n",
    "missing_indices = [(row, col) for row in range(data.shape[0]) for col in range(data.shape[1])]\n",
    "random_missing_indices = np.random.choice(len(missing_indices), size=num_missing, replace=False)\n",
    "\n",
    "for index in random_missing_indices:\n",
    "    row, col = missing_indices[index]\n",
    "    data.iat[row, col] = np.nan\n",
    "\n",
    "print(\"Dataset with Missing Values:\")\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Build your pipeline** to preprocess the dataset.\n",
    "2. **Test your pipeline** by fitting it to the Iris dataset and transforming it.\n",
    "3. **Review the processed data** and reflect on how the pipeline simplifies your workflow.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
