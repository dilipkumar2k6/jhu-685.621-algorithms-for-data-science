{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>Programming Assignment 2 (100 points total)</b></h1>\n",
    "<h3 align=\"center\"><b>Due at the end of Module 14</b></h3><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: MNIST Feature Extraction and Classification (50 Points Total)\n",
    "\n",
    "### **Objective**  \n",
    "In this question, you will explore **feature extraction** and **image classification** using the **MNIST handwritten digit dataset**. Your task is to preprocess raw image data, apply the **2D Discrete Cosine Transform (DCT)**, extract directionally informative coefficients using **frequency masks**, and conduct **dimensionality reduction via eigen decomposition**. You will then use the resulting features to train and compare multiple **classification algorithms**, including traditional machine learning and deep learning approaches.\n",
    "\n",
    "- **Dataset:** [MNIST Handwritten Digit Dataset](https://www.openml.org/d/554)  \n",
    "- **Focus Areas:** **Signal-based feature engineering**, **dimensionality reduction**, **supervised classification**, and **model comparison**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 1: Preprocessing and Visualization (10 Points)**\n",
    "#### **Instructions:**\n",
    "1. Load the **MNIST Dataset** and inspect its structure (e.g., flattened vector, first column label, no. of observations).\n",
    "   You can use the following code below:\n",
    "```python\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "```\n",
    "2. Display example images of each written number 0-9. \n",
    "3. Final dataset must include representative samples from each digit class (at least 100 per class). We understand compute limitations and thus do not require all observations but you can use all if you so choose.\n",
    "\n",
    "#### **Deliverables:**\n",
    "- 9 black & white images of an example of a handwritten digit from the dataset\n",
    "- Output showing how many observations and features \n",
    "- Proof that you have a representative sample from each class\n",
    "---\n",
    "\n",
    "### **Part 2: Feature Engineering using Eigen Decompoosition (15 points)**\n",
    "#### **Instructions:**\n",
    "1. Using `scipy.fft.dct` or `scipy.fftpack.dct` apply the **2D Discrete Cosine Transform** on each 28x28 image.\n",
    "2. Using the directional masks created using the code below extract the **directional coefficients** from each direction.\n",
    "   ```python\n",
    "   def create_custom_dct_masks(size=28):\n",
    "      h_mask = np.zeros((size, size), dtype=bool)\n",
    "      v_mask = np.zeros((size, size), dtype=bool)\n",
    "      d_mask = np.zeros((size, size), dtype=bool)\n",
    "\n",
    "      for i in range(size):\n",
    "         for j in range(size):\n",
    "               # Horizontal mask: upper triangle including diagonal\n",
    "               if i >= j:\n",
    "                  h_mask[i, j] = True\n",
    "               # Vertical mask: lower triangle including diagonal\n",
    "               if j >= i:\n",
    "                  v_mask[i, j] = True\n",
    "               # Diagonal mask: band near the diagonal\n",
    "               if abs(i - j) <= 1:\n",
    "                  d_mask[i, j] = True\n",
    "\n",
    "      return h_mask, v_mask, d_mask\n",
    "   ```\n",
    "3. For each directional component, **flatten the selected masked DCT coefficients** and create a matrix of samples.\n",
    "4. Compute the covariance matrix and perform **eigen decomposition**\n",
    "5. For each of the three directions, **retain the top 20 eigenvectors**\n",
    "6. Concatenate the **three sets of 20-dimensional features** (total 60 features per sample) to represent your final feature representation\n",
    "\n",
    "#### **Deliverables:**\n",
    "- 60 x number of observations dataset to use for supervised learning classification\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 3: Classification Algorithms (25 Points)**\n",
    "\n",
    "#### **Instructions:**\n",
    "1. **Train a supervised classification model** using the reduced feature set generated in **Part 2**. You may use any built-in method from `sklearn` (e.g., KNN, Random Forest, SVM, etc.).  \n",
    "   - Evaluate model performance (e.g., accuracy, confusion matrix).  \n",
    "   - **Interpret the model**: What patterns does it learn? Which features seem important?\n",
    "\n",
    "2. **Train a second model using your own SVM implementation** from Homework 3.  \n",
    "   - You may choose a **linear or RBF kernel**.  \n",
    "   - Use the same feature set from Part 2.  \n",
    "   - Discuss performance, convergence, and **interpret the model behavior** compared to the built-in one.\n",
    "\n",
    "3. **Compare model performance** between your `sklearn` classifier and your custom SVM.  \n",
    "   - Use **plots** (accuracy bars, confusion matrices, etc.) and **textual analysis** to highlight key differences.  \n",
    "   - Consider trade-offs in **accuracy**, **training time**, and **model flexibility**.\n",
    "\n",
    "4. **Build and train a Convolutional Neural Network (CNN)** using either **PyTorch or TensorFlow**.  \n",
    "   - Input should be the **raw 28×28 image** (not the reduced feature set).  \n",
    "   - You may use standard architectures (e.g., 2 convolutional layers + dense layers).  \n",
    "   - Train and evaluate the CNN on the same subset of data.\n",
    "\n",
    "5. **Compare and analyze CNN vs. DCT-based models.**  \n",
    "   - Report the **accuracy of all three models** (built-in, custom SVM, CNN).  \n",
    "   - Provide a thoughtful explanation of **why the CNN may outperform or underperform** traditional models.  \n",
    "   - Consider factors like input representation, feature learning, inductive bias, and model complexity.\n",
    "\n",
    "#### **Deliverables:**\n",
    "- Code for all three models (sklearn classifier, custom SVM, CNN).\n",
    "- Accuracy reports and visual comparisons (e.g., bar charts, confusion matrices).\n",
    "- A short written analysis comparing performance, highlighting **why results differ**, **algorithm complexity**, and discussing **model interpretability** vs. accuracy.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Considerations**\n",
    "✅ **Logical Flow:** The problem follows a structured pipeline: **Image Reshaping → DCT Feature Extraction → Masking → Eigen Decomposition → Classification**  \n",
    "✅ **Feature Engineering Emphasis:** Focuses on building compact, informative features using **directional DCT coefficients** and **eigenvectors**, not just using raw pixels.  \n",
    "✅ **Algorithmic Thinking:** Requires understanding of **signal processing**, **linear algebra** (e.g., eigen decomposition, projections), and **classification pipelines**.    \n",
    "✅ **Model Comparison:** Involves evaluating and comparing **sklearn models**, a **custom SVM**, and a **CNN**, encouraging reflection on strengths of different classification algorithms.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Good luck! 🚀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Design of Experiments (25 Points Total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells you’ll be provided with code that defines the initial ground object box (with latitude and longitude boundaries) and runs the simulation. \n",
    "\n",
    "As background, the simulation randomly selects a ground object location within a defined box and an aircraft’s starting position within another (scaled) box. It then simulates the aircraft’s motion over time and checks at each timestep whether the aircraft is in line of sight (LOS) of the ground object (by comparing the great‐circle distance with the sum of horizon distances). \n",
    "\n",
    "The outcome is recorded as a binary **“target”** variable:  \n",
    "- `0` for detection (LOS exists)  \n",
    "- `1` for no detection (no LOS)\n",
    "\n",
    "> **Important:** You are free to adjust the ground object latitude box (keeping approximately the same size) to any geographic region of interest to you. This will allow you to explore the effects of location on LOS detection.\n",
    "\n",
    "Your overall task is to **build upon the simulation output by training a classification model and performing a detailed statistical analysis**. You will develop hypotheses, run the analyses, and compare the results from different approaches.\n",
    "\n",
    "Your answers should include:\n",
    "- Code\n",
    "- Outputs (e.g., confusion matrices, feature importance plots, ANOVA tables)\n",
    "- Written explanations\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Background and Hypothesis (5 points)\n",
    "\n",
    "**Question:**  \n",
    "Briefly describe, in your own words, what the simulation code is doing. Your explanation should cover:\n",
    "\n",
    "- How the simulation uses geographic bounding boxes to set up the ground object and aircraft positions.\n",
    "- How the simulation determines if LOS exists between the ground object and the aircraft.\n",
    "- What the “target” variable represents.\n",
    "\n",
    "**Additionally:**  \n",
    "Propose a **hypothesis** about which parameters (e.g., aircraft altitude or initial aircraft longitude) you expect to have the greatest influence on LOS detection, and briefly justify your reasoning.\n",
    "\n",
    "> **Note:** You do not need to fully understand every detail of the simulation code, focus on the overall purpose and mechanism as described above. Also, feel free to adjust the ground object latitude box (while maintaining a similar size) to a location of your interest before proceeding with the analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Building a Classification Model (7 points)\n",
    "\n",
    "**Question:**  \n",
    "Using the simulation output (stored in a DataFrame named `df` with columns including:\n",
    "\n",
    "- `ground_lat`, `ground_lon`, `ground_alt`\n",
    "- `init_plane_lat`, `init_plane_lon`\n",
    "- `plane_alt`, `plane_speed`, `plane_heading`\n",
    "- `target`\n",
    "\n",
    "Complete the following tasks:\n",
    "\n",
    "1. Separate the features (`X`) and the target variable (`y`).\n",
    "2. Split the data into an 80-20 train-test split.\n",
    "3. Train a **Random Forest classifier** on the training set.\n",
    "4. Evaluate the model by computing the **accuracy** on both the training and test sets and **visualizing the confusion matrices**.\n",
    "\n",
    "**Discussion:**  \n",
    "Explain your **initial hypothesis** regarding which features might most strongly influence LOS detection, and comment on whether your model’s performance and the confusion matrices align with your expectations.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: Performing ANOVA and Logistic Regression (7 points)\n",
    "\n",
    "**Question:**  \n",
    "Using the `statsmodels` module, perform a **statistical analysis** on the training data by:\n",
    "\n",
    "1. Fitting an **Ordinary Least Squares (OLS)** model using a formula that includes all the features (e.g.,  \n",
    "   `target ~ ground_lat + ground_lon + ground_alt + init_plane_lat + init_plane_lon + plane_alt + plane_speed + plane_heading`)  \n",
    "   and generating an **ANOVA table**.\n",
    "\n",
    "2. Fitting a **logistic regression model** (which is more appropriate for binary outcomes) with the same formula.\n",
    "\n",
    "3. Reporting and comparing the results, particularly highlighting **which features are statistically significant** in both models.\n",
    "\n",
    "**Discussion:**  \n",
    "Formulate a **hypothesis** on which features you expect to be statistically significant in explaining LOS detection. Explain how the ANOVA and logistic regression results support or contradict your hypothesis.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Comparative Analysis and Critical Discussion (6 points)\n",
    "\n",
    "**Question:**  \n",
    "Compare the insights obtained from your **Random Forest classifier** (particularly the feature importance scores) with the findings from your **ANOVA table** and **logistic regression summary**. Address the following:\n",
    "\n",
    "- How do the Random Forest feature importance scores compare with the significance levels (e.g., p-values) from the ANOVA and logistic regression outputs?\n",
    "- What do these comparisons reveal about the key parameters affecting LOS detection in the simulation?\n",
    "- Based on your analysis, propose potential improvements to the simulation or suggest further experiments to enhance understanding of LOS detection.\n",
    "\n",
    "**Discussion:**  \n",
    "In your written analysis, clearly state your **conclusions**, supporting them with **evidence** from your code outputs and plots. Make sure your discussion is well-reasoned and data-driven.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------\n",
    "# Define the Ground Object box (ground object region)\n",
    "# -----------------------\n",
    "ground_lon_min, ground_lat_min = -82, 27.5\n",
    "ground_lon_max, ground_lat_max = -80, 29.0\n",
    "ground_width = ground_lon_max - ground_lon_min  # 2.0 degrees\n",
    "ground_height = ground_lat_max - ground_lat_min   # 1.5 degrees\n",
    "\n",
    "# Compute the center of the ground box\n",
    "center_lon = (ground_lon_min + ground_lon_max) / 2\n",
    "center_lat = (ground_lat_min + ground_lat_max) / 2\n",
    "\n",
    "# -----------------------\n",
    "# Define the Aircraft bounding box (30% smaller than the 50x area box)\n",
    "# -----------------------\n",
    "# Scale up dimensions for a 50x area then reduce by 30%\n",
    "scale_factor = 50**0.5\n",
    "aircraft_width = ground_width * scale_factor * 0.7\n",
    "aircraft_height = ground_height * scale_factor * 0.7\n",
    "\n",
    "# Center the aircraft box on the ground box center.\n",
    "aircraft_lon_min = center_lon - aircraft_width / 2\n",
    "aircraft_lon_max = center_lon + aircraft_width / 2\n",
    "aircraft_lat_min = center_lat - aircraft_height / 2\n",
    "aircraft_lat_max = center_lat + aircraft_height / 2\n",
    "\n",
    "# -----------------------\n",
    "# Visualization: Plotting Both Boxes\n",
    "# -----------------------\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Add geographic features.\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "# Draw the Ground Object box (red).\n",
    "ground_rect = mpatches.Rectangle(\n",
    "    (ground_lon_min, ground_lat_min),\n",
    "    ground_width,\n",
    "    ground_height,\n",
    "    linewidth=2,\n",
    "    edgecolor='red',\n",
    "    facecolor='none',\n",
    "    transform=ccrs.PlateCarree()\n",
    ")\n",
    "ax.add_patch(ground_rect)\n",
    "ax.text((ground_lon_min + ground_lon_max) / 2, ground_lat_max,\n",
    "        \"Ground Object\", color='red',\n",
    "        ha='center', va='bottom', transform=ccrs.PlateCarree())\n",
    "\n",
    "# Draw the Aircraft bounding box (blue).\n",
    "aircraft_rect = mpatches.Rectangle(\n",
    "    (aircraft_lon_min, aircraft_lat_min),\n",
    "    aircraft_width,\n",
    "    aircraft_height,\n",
    "    linewidth=2,\n",
    "    edgecolor='blue',\n",
    "    facecolor='none',\n",
    "    transform=ccrs.PlateCarree()\n",
    ")\n",
    "ax.add_patch(aircraft_rect)\n",
    "ax.text((aircraft_lon_min + aircraft_lon_max) / 2, aircraft_lat_max,\n",
    "        \"Aircraft Box\", color='blue',\n",
    "        ha='center', va='bottom', transform=ccrs.PlateCarree())\n",
    "\n",
    "# Set the extent to show both boxes with a margin.\n",
    "margin_lon = 5\n",
    "margin_lat = 5\n",
    "ax.set_extent([aircraft_lon_min - margin_lon, aircraft_lon_max + margin_lon,\n",
    "               aircraft_lat_min - margin_lat, aircraft_lat_max + margin_lat],\n",
    "              crs=ccrs.PlateCarree())\n",
    "\n",
    "plt.title(\"Ground Object Region and Aircraft Region\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Earth's radius in meters\n",
    "R = 6371000\n",
    "\n",
    "# Simulation parameters\n",
    "total_time = 3600  # seconds (1 hour)\n",
    "dt = 10            # time step in seconds\n",
    "num_steps = total_time // dt\n",
    "\n",
    "# Number of simulation runs\n",
    "num_runs = 10000\n",
    "\n",
    "# -----------------------\n",
    "# Helper Functions\n",
    "# -----------------------\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate the great-circle distance between two points (in meters).\"\"\"\n",
    "    lat1_rad, lon1_rad = math.radians(lat1), math.radians(lon1)\n",
    "    lat2_rad, lon2_rad = math.radians(lat2), math.radians(lon2)\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def update_position(lat, lon, speed, heading, dt):\n",
    "    \"\"\"\n",
    "    Update position based on current lat/lon, speed (m/s), heading (degrees),\n",
    "    and time step dt. Uses a simple spherical approximation.\n",
    "    \"\"\"\n",
    "    distance = speed * dt\n",
    "    heading_rad = math.radians(heading)\n",
    "    delta_north = distance * math.cos(heading_rad)\n",
    "    delta_east = distance * math.sin(heading_rad)\n",
    "    delta_lat = (delta_north / R) * (180 / math.pi)\n",
    "    delta_lon = (delta_east / (R * math.cos(math.radians(lat)))) * (180 / math.pi)\n",
    "    new_lat = lat + delta_lat\n",
    "    new_lon = lon + delta_lon\n",
    "    new_lon = (new_lon + 180) % 360 - 180  # normalize longitude\n",
    "    new_lat = max(min(new_lat, 90), -90)   # constrain latitude\n",
    "    return new_lat, new_lon\n",
    "\n",
    "def horizon_distance(alt):\n",
    "    \"\"\"\n",
    "    Calculate the horizon distance (in meters) for a given altitude 'alt'\n",
    "    using the approximation: distance ≈ √(2 * R * alt)\n",
    "    \"\"\"\n",
    "    return math.sqrt(2 * R * alt)\n",
    "\n",
    "# -----------------------\n",
    "# Simulation Function\n",
    "# -----------------------\n",
    "def simulate_run():\n",
    "    # Choose a random ground object location within the ground box.\n",
    "    ground_lon = random.uniform(ground_lon_min, ground_lon_max)\n",
    "    ground_lat = random.uniform(ground_lat_min, ground_lat_max)\n",
    "    ground_alt = 1.5  # observer height in meters\n",
    "\n",
    "    # Choose a random aircraft initial position within the aircraft bounding box.\n",
    "    init_plane_lat = random.uniform(aircraft_lat_min, aircraft_lat_max)\n",
    "    init_plane_lon = random.uniform(aircraft_lon_min, aircraft_lon_max)\n",
    "\n",
    "    # Randomly select the aircraft altitude between 150 ft and 65,000 ft (converted to meters).\n",
    "    plane_alt = random.uniform(150 * 0.3048, 65000 * 0.3048)\n",
    "\n",
    "    # Aircraft speed and heading.\n",
    "    plane_speed = 250  # m/s (~900 km/h)\n",
    "    plane_heading = random.uniform(0, 360)  # degrees\n",
    "\n",
    "    # Set initial aircraft position.\n",
    "    plane_lat = init_plane_lat\n",
    "    plane_lon = init_plane_lon\n",
    "\n",
    "    # Flag for line-of-sight occurrence.\n",
    "    los_occurred = False\n",
    "\n",
    "    for step in range(int(num_steps) + 1):\n",
    "        # Calculate the great-circle distance between ground object and aircraft.\n",
    "        distance = haversine(ground_lat, ground_lon, plane_lat, plane_lon)\n",
    "        # Calculate horizon distances.\n",
    "        d_ground = horizon_distance(ground_alt)\n",
    "        d_plane = horizon_distance(plane_alt)\n",
    "        # If LOS exists at this timestep, flag it.\n",
    "        if distance <= (d_ground + d_plane):\n",
    "            los_occurred = True\n",
    "            break\n",
    "        # Update aircraft position.\n",
    "        plane_lat, plane_lon = update_position(plane_lat, plane_lon, plane_speed, plane_heading, dt)\n",
    "\n",
    "    # If LOS occurred at least once, target is 0, otherwise 1.\n",
    "    target = 0 if los_occurred else 1\n",
    "\n",
    "    return {\n",
    "        \"ground_lat\": ground_lat,\n",
    "        \"ground_lon\": ground_lon,\n",
    "        \"ground_alt\": ground_alt,\n",
    "        \"init_plane_lat\": init_plane_lat,\n",
    "        \"init_plane_lon\": init_plane_lon,\n",
    "        \"plane_alt\": plane_alt,\n",
    "        \"plane_speed\": plane_speed,\n",
    "        \"plane_heading\": plane_heading,\n",
    "        \"target\": target\n",
    "    }\n",
    "\n",
    "# -----------------------\n",
    "# Run the Simulation and Save Results in a DataFrame\n",
    "# -----------------------\n",
    "results = [simulate_run() for _ in range(num_runs)]\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate the fraction of runs with target = 1 (i.e. no LOS ever occurred)\n",
    "fraction_no_los = df[\"target\"].mean()\n",
    "print(f\"Fraction of runs with no LOS (target=1): {fraction_no_los:.4f}\")\n",
    "print(\"\\nDataFrame head:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Generative Models & Sequence Architectures in NLP (25 Points Total)\n",
    "\n",
    "### **Objective**  \n",
    "This question explores modern generative modeling techniques and neural architectures used for sequence data. The focus is on understanding **how GANs, VAEs, and Seq2Seq models**, how they are trained, and how they handle **discrete language data**. You will analyze their design and evaluate basic implementations using pre-trained or lightweight models via **HuggingFace** or **TensorFlow Hub**.\n",
    "\n",
    "- **Topics Covered:** Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Sequence-to-Sequence (Seq2Seq) models  \n",
    "- **Focus Areas:** Basic architectural understanding, loss function comparison, implementation insight, and training strategy analysis\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 1: Model Comparison and Demonstration (25 Points)**\n",
    "\n",
    "#### **Instructions:**\n",
    "1. **Select two model classes** from the list below:\n",
    "   - GANs (e.g., TextGAN, SeqGAN)\n",
    "   - VAEs (e.g., VAE for text generation)\n",
    "   - Seq2Seq (e.g., encoder-decoder with attention)\n",
    "\n",
    "2. For each selected model, do the following:\n",
    "\n",
    "   - **(5 pts)** **Load and demonstrate a pre-trained model** using either [🤗 HuggingFace Transformers](https://huggingface.co/models) or [TensorFlow Hub](https://tfhub.dev/).  \n",
    "     - Run the model on a sample text input.  \n",
    "     - Show the generated output or the model's prediction.  \n",
    "     - Briefly explain how the input and output are represented.\n",
    "\n",
    "   - **(5 pts)** Describe the model architecture in your own words. What are the key layers (e.g., encoder/decoder, attention, positional encoding)? What role does each play?\n",
    "\n",
    "   - **(5 pts)** Identify and explain the **loss function** used for training. How does it handle discrete or sequential data?\n",
    "\n",
    "   - **(5 pts)** Discuss one **challenge in training** this model on text (e.g., instability, exposure bias, overfitting) and a technique used to mitigate it.\n",
    "\n",
    "3. **(5 pts)** Write a short comparison paragraph (150–250 words) addressing the following:\n",
    "   - What kinds of tasks is each model better suited for?\n",
    "   - Which model is more interpretable or efficient?\n",
    "   - Which is easier to fine-tune or deploy?\n",
    "\n",
    "#### **Deliverables:**\n",
    "- Code cells demonstrating the two selected models (using HuggingFace or TensorFlow Hub) with at least one input/output example per model.\n",
    "- Written responses covering architecture, loss function, training challenge, and model comparison.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
