{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>Homework Assignment 3 (100 points total)</b></h1>\n",
    "<h3 align=\"center\"><b>Assigned at the start of Module 9</b></h3>\n",
    "<h3 align=\"center\"><b>Due at the end of Module 12</b></h3><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Supervised Learning Regression\n",
    "\n",
    "## Build a supervised learning linear regression model (scikit-learn permitted) (30 points total)\n",
    "\n",
    "In this question, you will analyze a housing dataset and investigate the impact of multicollinearity on a Linear Regression model. You will then apply Ridge and Lasso Regression to mitigate these effects and compare their performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Data Acquisition & Preprocessing (5 points)**\n",
    "- **Dataset** Use the California Housing Dataset (available via `sklearn.datasets`).\n",
    "- **Exploratory Data Analysis (EDA):**\n",
    "    - Identify and describe the feature distributions.\n",
    "    - Check for multicollinearity using a correlation heatmap and Variance Inflation Factor (VIF).\n",
    "    - Select a subset of features that introduce multicollinearity.\n",
    "- **Preprocessing**:\n",
    "    - Standardize the dataset to ensure consistent scaling.\n",
    "    - Split the data into training (80%) and testing (20%) sets.\n",
    "  \n",
    "---\n",
    "\n",
    "### 2. **Regression Model Development (10 points)**\n",
    "- **Train a Linear Regression Model:**\n",
    "    - Fit a standard Linear Regression model to the data.\n",
    "    - Report the coefficients and explain their significance.\n",
    "    - Evaluate the model using MSE, RMSE, and $R^2$.\n",
    "- **Detect Multicollinearity Issues:**\n",
    "    - Identify unstable coefficients or unusually large magnitudes in the model.\n",
    "    - Explain how multicollinearity affects interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Regularization Techniques: Ridge vs. Lasso (10 points)**\n",
    "- **Apply Ridge Regression (L2 Regularization):**\n",
    "    - Train a Ridge model with various values of $\\lambda$(e.g., 0.1, 1, 10, 100).\n",
    "    - Plot coefficient shrinkage as $\\lambda$ increases.\n",
    "    - Evaluate model performance using MSE, RMSE, and $R^2$.\n",
    "- **Apply Lasso Regression (L1 Regularization):**\n",
    "    - Train a Lasso model with the same $\\lambda$ values.\n",
    "    - Plot coefficient shrinkage and identify features that are eliminated.\n",
    "    - Compare its performance to Ridge Regression.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Interpretation & Discussion (5 points)**\n",
    "- **Compare and interpret results:**\n",
    "    - How did Ridge and Lasso handle multicollinearity?\n",
    "    - Which model had better predictive accuracy?\n",
    "    - When would you use Ridge over Lasso (and vice versa)?\n",
    "- **Discuss implications for real-world regression problems:**\n",
    "    - If a model has too many irrelevant features, which method (Ridge or Lasso) would be more effective?\n",
    "    - How does regularization impact overfitting in high-dimensional datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Supervised Learning Classification  \n",
    "## Breast Cancer Prediction Using Feature Engineering & SVM (40 points total)\n",
    "\n",
    "In this question, you will build a classifier to predict the diagnosis of breast cancer (malignant vs. benign) using structured diagnostic data. You will preprocess features, engineer new ones, and evaluate multiple classification models, with a focus on implementing Support Vector Machines (SVMs) from scratch using quadratic programming.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Acquisition & Preprocessing (5 points)\n",
    "\n",
    "- **Dataset**: Use the [Breast Cancer Wisconsin (Diagnostic) Dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) (also available via `sklearn.datasets.load_breast_cancer()`).\n",
    "\n",
    "### Exploratory Data Analysis (EDA):\n",
    "- Examine the distribution of the target variable (`diagnosis`: M = malignant, B = benign).\n",
    "- Identify any missing or anomalous values.\n",
    "- Explore relationships between features such as:\n",
    "  - `mean radius`\n",
    "  - `mean texture`\n",
    "  - `mean smoothness`\n",
    "\n",
    "### Feature Engineering:\n",
    "- Encode the target variable (`diagnosis`) into binary:\n",
    "  - `1 = malignant`, `0 = benign`\n",
    "- Normalize continuous features using `StandardScaler` or `MinMaxScaler` (especially important for SVM).\n",
    "- Create interaction terms or polynomial features (e.g., `mean radius × mean texture`, `mean concavity²`) using `PolynomialFeatures` from `sklearn.preprocessing`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Model Training & Evaluation (20 points)\n",
    "\n",
    "Train the following classifiers:\n",
    "\n",
    "- **Logistic Regression** (baseline; use `scikit-learn`)\n",
    "- **Decision Tree Classifier** (interpretable; use `scikit-learn`)\n",
    "- **Support Vector Machine (SVM)**:\n",
    "  - Implement from scratch using the `cvxopt` quadratic programming solver\n",
    "  - Do **not** use `scikit-learn`'s `SVC` or `LinearSVC`\n",
    "\n",
    "### Evaluation Metrics:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- Confusion Matrix\n",
    "- ROC-AUC Curve\n",
    "\n",
    "Use appropriate plots to visualize performance (e.g., confusion matrix heatmap, ROC curves).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Hyperparameter Tuning (10 points)\n",
    "\n",
    "### Hyperparameter Tuning:\n",
    "- **Logistic Regression**: Tune regularization parameter `C`\n",
    "- **Decision Tree**: Tune `max_depth` and optionally `min_samples_leaf`\n",
    "- **SVM**: Try both linear and RBF kernels (implement both kernels)\n",
    "  - Linear Kernel - $K(x,x') = x^T x' $\n",
    "  - RBF kernel - $K(x,x') = \\exp(-\\gamma || x - x' ||^2)$\n",
    "    - where $\\gamma > 0$ is a parameter that defines the spread of the kernel\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Interpretation & Discussion (5 points)\n",
    "\n",
    "### Model Comparison:\n",
    "- Which model performed best overall?\n",
    "- Which model showed the most stability (i.e., smallest performance variance across folds)?\n",
    "- How did kernel choice in SVM influence classification performance?\n",
    "- Did feature scaling or polynomial features help the SVM?\n",
    "\n",
    "### Real-World Implications:\n",
    "- What are the consequences of **false negatives** in this breast cancer prediction task?\n",
    "- In a medical diagnosis context, would you prioritize **precision** or **recall**? Why?\n",
    "- Is your SVM implementation viable for use in clinical decision-making tools? What improvements would be necessary?\n",
    "\n",
    "---\n",
    "\n",
    "## Submission Guidelines:\n",
    "- Submit a Jupyter notebook (or `.py` script) with all code and plots\n",
    "- Include a brief summary of findings at the end of the notebook\n",
    "- Code should be clearly commented and structured\n",
    "\n",
    "---\n",
    "\n",
    "## Optional Extensions:\n",
    "- Implement grid search manually for SVM kernel and `C` tuning\n",
    "- Use SHAP or LIME for post hoc model explanation (especially for the logistic model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q3: Custom K-Means Clustering Framework**\n",
    "\n",
    "## Build a custom K-Means clustering framework from scratch (scikit-learn not permitted) (30 points total)\n",
    "\n",
    "In this question, you will implement the K-Means clustering algorithm from scratch and develop a framework that evaluates multiple candidate numbers of clusters. You will apply your framework to the **Wholesale Customers Dataset** from the UCI Machine Learning Repository, which is well-suited for clustering-based customer segmentation. **Note:** For the clustering analysis, you should drop the **Channel** and **Region** columns, focusing solely on the spending features. Additionally, you will analyze the runtime of your algorithm and provide an asymptotic complexity analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Data Acquisition & Preprocessing (5 points)**\n",
    "- **Dataset:** Download the **Wholesale Customers Dataset** from the UCI Machine Learning Repository.\n",
    "- **Exploratory Data Analysis (EDA):**\n",
    "  - Identify missing or inconsistent values.\n",
    "  - Analyze the distributions of features.\n",
    "  - Apply normalization or standardization if necessary to ensure the data is suitable for clustering.\n",
    "  - **Important:** Remove the **Channel** and **Region** columns before performing clustering analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Problem Formulation & Algorithm Design (10 points)**\n",
    "- **Objective:** Clearly define the goal of clustering in the context of customer segmentation using the Wholesale Customers dataset.\n",
    "- **Algorithm Overview:**\n",
    "  - Provide a brief explanation of the K-Means clustering algorithm, detailing its main steps:\n",
    "    - **Initialization:** Selecting initial centroids.\n",
    "    - **Assignment:** Allocating data points to the nearest centroid.\n",
    "    - **Update:** Recalculating centroids based on the current cluster members.\n",
    "- **Framework Requirements:**\n",
    "  - Develop a framework that accepts a list of candidate numbers of clusters (e.g., [2, 3, 4, 5, 6]).\n",
    "  - For each candidate value, run your custom K-Means algorithm.\n",
    "  - Compute clustering metrics (such as Within-Cluster Sum of Squares (WCSS) and silhouette score—metrics introduced in lecture) for each clustering result.\n",
    "  - Select and justify the best number of clusters based on your computed metrics.\n",
    "- **Considerations:**\n",
    "  - Discuss any assumptions you make (e.g., initialization methods, convergence criteria).\n",
    "  - Identify potential challenges in applying K-Means to this dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Implementation & Runtime Analysis (10 points)**\n",
    "- **Implementation:**\n",
    "  - Write your own implementation of the K-Means algorithm in Python without using any built-in clustering libraries.\n",
    "  - Integrate the algorithm into a framework that automates the process for multiple candidate numbers of clusters.\n",
    "- **Runtime Analysis:**\n",
    "  - Measure and report the total runtime of your algorithm for different candidate values.\n",
    "  - Analyze the computational complexity of your implementation. Provide the asymptotic notation (e.g., O(n × k × i)), where:\n",
    "    - *n* is the number of data points,\n",
    "    - *k* is the number of clusters,\n",
    "    - *i* is the number of iterations until convergence.\n",
    "- **Documentation:**\n",
    "  - Ensure your code is well-documented, with comments explaining the functionality of key components.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Evaluation & Reflection (5 points)**\n",
    "- **Result Comparison:**\n",
    "  - Compare the clustering results obtained for each candidate number of clusters using your chosen metrics.\n",
    "  - Identify which number of clusters produced the best overall performance.\n",
    "- **Discussion:**\n",
    "  - Analyze how the resultant clusters relate back to the physical world. For example, interpret the clusters in terms of customer segmentation by exploring patterns such as purchasing behavior, spending habits, or other relevant characteristics.\n",
    "  - Discuss what the cluster profiles might imply for real-world applications, such as targeted marketing strategies or business decision-making.\n",
    "  - Reflect on the trade-offs between clustering quality and runtime performance.\n",
    "\n",
    "---\n",
    "\n",
    "This question is designed to deepen your understanding of unsupervised learning, algorithm development, and performance evaluation. Be sure to clearly justify your design choices and critically analyze your results throughout the report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
