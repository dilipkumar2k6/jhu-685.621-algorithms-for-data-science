{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>Programming Assignment 1 (100 points total)</b></h1>\n",
    "<h3 align=\"center\"><b>Due at the end of Module 7</b></h3><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 1: Exploratory Data Analysis and Preprocessing**\n",
    "\n",
    "### **Objective**  \n",
    "In this question, you will conduct a structured exploratory data analysis (EDA) and preprocess the **Wine Quality Dataset** to prepare it for downstream analysis. This includes computing **summary statistics**, detecting and removing **outliers using Mahalanobis distance**, applying **feature normalization**, and performing **dimensionality reduction with PCA**. Throughout, you will be required to analyze your results and justify your methodological choices.\n",
    "\n",
    "- **Dataset:** [Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)  \n",
    "- **Focus Areas:** Algorithm analysis, data interpretation, and preprocessing strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## **Question 1: Exploratory Data Analysis and Preprocessing (30 Points)**\n",
    "\n",
    "### **Part 1: Summary Statistics (5 Points)**\n",
    "#### **Instructions:**\n",
    "1. Load the **Wine Quality Dataset** and inspect its structure (e.g., feature types, missing values, summary statistics).\n",
    "2. Compute the following descriptive statistics for each feature, both overall and grouped by wine quality rating:\n",
    "   - Minimum, Maximum\n",
    "   - Mean, Trimmed Mean (5%)\n",
    "   - Standard Deviation\n",
    "   - Skewness, Kurtosis\n",
    "3. Present results in a **clear table**.\n",
    "4. Provide a written **interpretation** of what these statistics reveal about the dataset.\n",
    "\n",
    "#### **Deliverables:**\n",
    "- Code implementation for computing summary statistics.\n",
    "- A table summarizing computed values.\n",
    "- A written analysis of key insights.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 2: Data Visualization (5 Points)**\n",
    "#### **Instructions:**\n",
    "1. Create **scatter plots or pair plots** to visualize relationships between two numerical features and wine quality.\n",
    "2. Identify any **patterns, trends, or clusters** in the data.\n",
    "3. Discuss whether **certain features appear to separate wine quality levels** more effectively.\n",
    "\n",
    "#### **Deliverables:**\n",
    "- Code for generating visualizations.\n",
    "- A written discussion of key observations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 3: Outlier Detection and Removal using Mahalanobis Distance (5 Points)**\n",
    "#### **Instructions:**\n",
    "1. **Use the provided pairwise ellipse plot method** (which builds on the Mahalanobis distance) to assess outliers in the dataset.\n",
    "2. Select **at least three distinct feature pairs** for visualization.\n",
    "3. Develop a **numerical outlier metric** based on Mahalanobis distance to systematically identify extreme values.\n",
    "4. Implement an **algorithm that removes observations identified as outliers** based on this metric.\n",
    "5. Justify the **choice of threshold** for outlier removal and explain why Mahalanobis distance is appropriate for multivariate data.\n",
    "\n",
    "#### **Deliverables:**\n",
    "- Code implementing the outlier detection and removal algorithm.\n",
    "- Pairwise ellipse plots for at least three feature pairs.\n",
    "- A written explanation of the metric used for outlier detection and removal, including justification of the threshold.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 4: Feature Scaling and Normalization (5 Points)**\n",
    "#### **Instructions:**\n",
    "1. Apply **Min-Max Normalization** to scale all numerical features between 0 and 1.\n",
    "2. Verify that the transformed features meet the expected range.\n",
    "3. Explain why normalization is essential for analyses such as PCA.\n",
    "\n",
    "#### **Deliverables:**\n",
    "- Code for Min-Max Normalization.\n",
    "- A table comparing feature values before and after normalization.\n",
    "- A written explanation of why normalization is beneficial.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 5: Principal Component Analysis and Dimensionality Reduction (10 Points)**\n",
    "#### **Instructions:**\n",
    "1. Apply **PCA to the full dataset** and compute the **explained variance for each principal component**.\n",
    "2. Visualize the **cumulative explained variance** to determine how many principal components should be retained.\n",
    "3. Apply **PCA separately for different wine quality levels** and compare the variance explained.\n",
    "4. Discuss whether PCA helps reveal patterns that were not evident in the original features.\n",
    "\n",
    "#### **Deliverables:**\n",
    "- Code for PCA computation (built-in package is allowed).\n",
    "- A table showing explained variance for each principal component.\n",
    "- A discussion on the differences between applying PCA to the full dataset vs. subsets by wine quality.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Considerations**\n",
    "âœ… **Logical Flow:** The problem walks through **EDA â†’ Cleaning â†’ Transformation â†’ PCA**  \n",
    "âœ… **Focus on Analysis & Justification:** You must **explain your choices** rather than just implement code.  \n",
    "âœ… **Algorithmic Thinking:** Requires **metric development**, use of **Mahalanobis distance**, and **PCA interpretation**.  \n",
    "\n",
    "---\n",
    "\n",
    "Good luck! ðŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality wine_type  \n",
       "0      9.4        5       red  \n",
       "1      9.8        5       red  \n",
       "2      9.8        5       red  \n",
       "3      9.8        6       red  \n",
       "4      9.4        5       red  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load red and white wine datasets from UCI Machine Learning Repository\n",
    "url_red = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "url_white = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "\n",
    "df_red = pd.read_csv(url_red, sep=';')\n",
    "df_white = pd.read_csv(url_white, sep=';')\n",
    "df_red['wine_type'] = 'red'\n",
    "df_white['wine_type'] = 'white'\n",
    "df_wine = pd.concat([df_red, df_white], axis=0, ignore_index=True)\n",
    "\n",
    "df_wine.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 2: Statistical Algorithms (30 Points)**\n",
    "\n",
    "### **Objective**  \n",
    "In this question, you will implement a **NaÃ¯ve Bayes classifier from scratch** (without using built-in machine learning libraries). You will:\n",
    "1. **Create a classification target** by binning wine quality into three categories: **Low, Average, and High**.\n",
    "2. **Implement a NaÃ¯ve Bayes classifier** without using built-in ML functions.\n",
    "3. **Analyze the runtime complexity** of your implementation.\n",
    "4. **Compare model performance** using:\n",
    "   - **Raw dataset** (before preprocessing)\n",
    "   - **Preprocessed dataset** (from Question 1)\n",
    "\n",
    "Through this analysis, you will evaluate how data preprocessing affects classification performance and runtime efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 1: Creating a Classification Target (5 Points)**\n",
    "1. Using the `quality` column from the Wine Quality Dataset, **convert wine quality into three categories**:\n",
    "   - **Low Quality:** `quality â‰¤ 5`\n",
    "   - **Average Quality:** `quality = 6`\n",
    "   - **High Quality:** `quality â‰¥ 7`\n",
    "2. Store this as a new column: `quality_category`\n",
    "3. Ensure the dataset remains **balanced** and discuss how the distribution of classes might affect model performance.\n",
    "\n",
    "**Deliverables:**\n",
    "- Code to transform the target variable.\n",
    "- A frequency table showing the distribution of the three categories.\n",
    "- A written discussion on class distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 2: Implementing NaÃ¯ve Bayes from Scratch (15 Points)**\n",
    "You will **implement a NaÃ¯ve Bayes classifier without using built-in ML libraries**.\n",
    "\n",
    "### **Steps to Implement:**\n",
    "1. **Compute Prior Probabilities:**  \n",
    "   - Calculate the probability of each class (`P(Class)`).\n",
    "   \n",
    "2. **Compute Conditional Probabilities:**  \n",
    "   - For each feature, assume a **Gaussian (Normal) distribution** and compute:\n",
    "     $$ P(X | Class) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(X - \\mu)^2}{2\\sigma^2}} $$\n",
    "   - Use the **mean (Î¼) and standard deviation (Ïƒ)** per feature per class.\n",
    "\n",
    "3. **Implement the Prediction Function:**  \n",
    "   - Compute **posterior probabilities** for each class using Bayesâ€™ Theorem:\n",
    "     $$ P(Class | X) = \\frac{P(X | Class) P(Class)}{P(X)} $$\n",
    "   - Assign each observation to the class with the highest posterior probability.\n",
    "\n",
    "4. **Evaluate the Classifier:**  \n",
    "   - Implement an **accuracy function** to compare predicted vs. actual classes.\n",
    "\n",
    "**Deliverables:**\n",
    "- Python implementation of NaÃ¯ve Bayes (without built-in ML functions).\n",
    "- Code for prior probabilities, likelihood estimation, and classification.\n",
    "- An accuracy metric for model performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 3: Algorithm Runtime Analysis (5 Points)**\n",
    "1. **Derive the computational complexity** of your NaÃ¯ve Bayes implementation.\n",
    "2. Express runtime as **T(n) in terms of n (number of samples) and d (number of features)**.\n",
    "3. Provide the **asymptotic runtime** using **Big-O notation**.\n",
    "\n",
    "**Deliverables:**\n",
    "- Derivation of **T(n) runtime complexity**.\n",
    "- Asymptotic **Big-O analysis**.\n",
    "- A written explanation of how the runtime is affected by dataset size.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 4: Comparing Performance on Raw vs. Preprocessed Data (5 Points)**\n",
    "1. Train and evaluate the **NaÃ¯ve Bayes classifier on the raw dataset** (before preprocessing).\n",
    "2. Train and evaluate the **NaÃ¯ve Bayes classifier on the preprocessed dataset** (from Question 1).\n",
    "3. **Compare results**, considering:\n",
    "   - **Classification accuracy**\n",
    "   - **Computation time**\n",
    "   - **Impact of preprocessing on model performance**\n",
    "4. Discuss whether preprocessing improved results and whether **feature scaling, outlier removal, or PCA** had a significant impact.\n",
    "\n",
    "**Deliverables:**\n",
    "- Accuracy comparison table for **raw vs. preprocessed data**.\n",
    "- Computation time analysis for both datasets.\n",
    "- A written discussion on preprocessing impact.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "âœ… **Students implement a core ML algorithm from scratch**, reinforcing mathematical intuition.  \n",
    "âœ… **Runtime complexity analysis** encourages computational efficiency considerations.  \n",
    "âœ… **Comparing raw vs. preprocessed data** teaches the importance of data preparation in model performance.\n",
    "\n",
    "---\n",
    "\n",
    "Good luck! ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 3: Linear Programming vs. Particle Swarm Optimization (20 Points)**\n",
    "\n",
    "### **Objective**\n",
    "In this question, you will solve a **linear programming (LP) optimization problem** using **two different methods**:\n",
    "1. **Linear Programming (LP) Solver (`scipy.optimize.linprog`)**\n",
    "2. **Particle Swarm Optimization (PSO) (`pyswarms`)**\n",
    "\n",
    "You will then **compare and contrast the two approaches** in terms of **solution quality, computational efficiency, and robustness**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Problem Statement**\n",
    "You are given the following **linear objective function** to minimize:\n",
    "\n",
    "$ \\min_{x} \\quad f(x) = -4x_1 - 3x_2 $\n",
    "\n",
    "### **Subject to Constraints:**\n",
    "$ x_1 + 2x_2 \\leq 8 $ \n",
    "$ 3x_1 + x_2 \\leq 9 $\n",
    "$ x_1 \\geq 0, \\quad x_2 \\geq 0 $\n",
    "\n",
    "where:\n",
    "- $ (x_1, x_2) $ are the decision variables.\n",
    "- The constraints ensure feasible values for $x_1$ and $x_2$.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 1: Solve Using Linear Programming (LP) (7 Points)**\n",
    "1. **Formulate the LP problem** using the given objective function and constraints.\n",
    "2. **Use `scipy.optimize.linprog`** to solve for the optimal $x$.\n",
    "3. **Record the optimal solution $x^*$ and objective value $f(x^*)$.**\n",
    "\n",
    "**Deliverables:**\n",
    "- Python code implementing the LP solution.\n",
    "- The optimal solution $x^*$ and objective function value.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 2: Solve Using Particle Swarm Optimization (PSO) (7 Points)**\n",
    "1. Define the **same objective function** as a Python function.\n",
    "2. Implement **constraint handling** so that the constraints $Ax \\leq b$ and $x \\geq 0$ are satisfied.\n",
    "3. **Use `pyswarms`** to approximate the solution.\n",
    "4. **Record the optimal solution $x^*$ and objective value $f(x^*)$.**\n",
    "\n",
    "**Deliverables:**\n",
    "- Python code implementing the PSO solution.\n",
    "- The optimal solution $x^*$ and objective function value.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 3: Compare and Contrast LP vs. PSO (6 Points)**\n",
    "Write a **comparative analysis** of the two optimization methods based on:\n",
    "1. **Solution Accuracy:** How close was PSO to the exact LP solution?\n",
    "2. **Computational Efficiency:** Which method was faster? Why?\n",
    "3. **Robustness:** How does each method perform in more complex scenarios (e.g., non-convex problems)?\n",
    "4. **Use Cases:** When would you prefer **LP over PSO**, and vice versa?\n",
    "\n",
    "**Deliverables:**\n",
    "- A **written analysis** comparing LP vs. PSO.\n",
    "- A **table summarizing key differences**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "âœ… **Demonstrates the difference between exact (LP) and heuristic (PSO) methods**.  \n",
    "âœ… **Encourages computational analysis by comparing solution accuracy and runtime**.  \n",
    "âœ… **Prepares students to think critically about choosing optimization techniques in real-world problems**.  \n",
    "\n",
    "Good luck! ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 4: Bayesian Networks for Disease Diagnosis and Treatment Decision (20 Points)**\n",
    "\n",
    "## **Objective**\n",
    "In this problem, you will:\n",
    "1. **Construct a Bayesian Network** for medical diagnosis.\n",
    "2. **Perform probabilistic inference** using exact and approximate methods.\n",
    "3. **Analyze the runtime complexity** of different inference algorithms.\n",
    "4. **Evaluate the impact of graph structure on inference performance.**\n",
    "\n",
    "---\n",
    "\n",
    "## **Problem Statement**\n",
    "A hospital is developing an **AI-driven Bayesian Network** to assist in diagnosing patients. The system includes:\n",
    "\n",
    "- **Flu (F)** and **COVID-19 (C)** as potential diseases.\n",
    "- **Cough (K)** and **Fever (V)** as symptoms.\n",
    "- **COVID-19 Treatment (T)** as an intervention.\n",
    "- **Recovery (R)** depends on the disease and treatment.\n",
    "\n",
    "### **Bayesian Network Structure**\n",
    "      Flu       COVID-19\n",
    "       |        /\n",
    "       v       v\n",
    "    Fever   Cough\n",
    "        \\     |\n",
    "         v    v\n",
    "        Recovery\n",
    "           ^\n",
    "           |\n",
    "       Treatment\n",
    "\n",
    "### **Conditional Probability Tables (CPTs)**\n",
    "The following **CPTs** define the probabilistic relationships in the network:\n",
    "\n",
    "#### **Disease Probabilities**\n",
    "| Disease | P(Flu) | P(COVID-19) |\n",
    "|---------|--------|-------------|\n",
    "| True    | 0.12   | 0.08        |\n",
    "| False   | 0.88   | 0.92        |\n",
    "\n",
    "#### **Symptoms Given Disease**\n",
    "| Flu | COVID-19 | P(Fever) | P(Cough) |\n",
    "|-----|---------|----------|----------|\n",
    "| False | False | 0.01     | 0.02     |\n",
    "| False | True  | 0.85     | 0.60     |\n",
    "| True  | False | 0.90     | 0.70     |\n",
    "| True  | True  | 0.98     | 0.85     |\n",
    "\n",
    "#### **Treatment Decision**\n",
    "Doctors **only administer treatment if COVID-19 is present**:\n",
    "- $ P(Treatment | COVID-19) = 0.95 $\n",
    "- $ P(Treatment | \\neg COVID-19) = 0.05 $ (error rate)\n",
    "\n",
    "#### **Recovery Probabilities**\n",
    "| Flu | COVID-19 | Treatment | P(Recovery) |\n",
    "|-----|---------|-----------|-------------|\n",
    "| False | False | Any       | 0.99        |\n",
    "| False | True  | Yes       | 0.90        |\n",
    "| False | True  | No        | 0.50        |\n",
    "| True  | False | Any       | 0.85        |\n",
    "| True  | True  | Yes       | 0.80        |\n",
    "| True  | True  | No        | 0.30        |\n",
    "\n",
    "## **Part 1: Constructing the Bayesian Network (5 Points)**\n",
    "1. **Define the Bayesian Network structure** using `pgmpy`.\n",
    "2. **Assign conditional probability tables (CPTs)** to each node.\n",
    "3. **Ensure the network is valid and consistent.**\n",
    "\n",
    "**Deliverables:**\n",
    "- Python code defining the Bayesian Network.\n",
    "- Explanation of the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 2: Bayesian Inference (8 Points)**\n",
    "Compute the following probabilities using different inference algorithms:\n",
    "1. $ P(\\text{COVID-19} \\mid \\text{Fever} = \\text{True}, \\text{Cough} = \\text{True}) $\n",
    "2. $ P(\\text{Flu} \\mid \\text{Fever} = \\text{True}, \\text{Cough} = \\text{False}) $\n",
    "3. $ P(\\text{Treatment} \\mid \\text{Cough} = \\text{True}) $\n",
    "4. $ P(\\text{Recovery} \\mid \\text{Fever} = \\text{True}, \\text{Treatment} = \\text{True}) $\n",
    "\n",
    "Use:\n",
    "- **Exact Inference** (Variable Elimination)\n",
    "- **Approximate Inference** (Gibbs Sampling)\n",
    "\n",
    "**Deliverables:**\n",
    "- Python code implementing both inference methods.\n",
    "- Interpretation of results.\n",
    "\n",
    "---\n",
    "\n",
    "## **Part 3: Runtime Analysis (7 Points)**\n",
    "### **Step 1: Measure and Compare Runtime**\n",
    "1. Implement a function to **measure execution time** for both:\n",
    "   - **Variable Elimination** (exact inference).\n",
    "   - **Gibbs Sampling** (approximate inference).\n",
    "2. Run both algorithms on increasingly **larger networks** (e.g., by adding more symptoms or diseases).\n",
    "3. Plot runtime as a function of network size.\n",
    "\n",
    "### **Step 2: Theoretical Complexity Analysis**\n",
    "1. Analyze **the worst-case time complexity** of:\n",
    "   - **Variable Elimination** (Hint: related to treewidth of the graph).\n",
    "   - **Gibbs Sampling** (Hint: depends on number of iterations).\n",
    "2. Discuss how the **graph structure** (e.g., chain, tree, densely connected) impacts computational efficiency.\n",
    "\n",
    "### **Step 3: Interpretation**\n",
    "1. Based on your runtime measurements, which algorithm scales better?\n",
    "2. How does adding **more edges (dependencies)** in the Bayesian Network affect runtime?\n",
    "3. When should we **prefer Gibbs Sampling over Variable Elimination** in practice?\n",
    "\n",
    "**Deliverables:**\n",
    "- Python code measuring runtime.\n",
    "- A **runtime comparison graph**.\n",
    "- A **written explanation** discussing results.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "âœ… **Demonstrates Bayesian inference using exact and approximate algorithms.**  \n",
    "âœ… **Encourages students to evaluate algorithmic efficiency in probabilistic reasoning.**  \n",
    "âœ… **Teaches practical trade-offs between accuracy and computational cost.**  \n",
    "âœ… **Connects Bayesian Networks to Graph Algorithm complexity analysis.**\n",
    "\n",
    "Good luck! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
